# Context Engine MCP - Optimized Version
# Scientific Prompt Engineering + Philosophical Wisdom

# ========================================
# MCP Server Configuration
# ========================================
server:
  name: "context-engine-mcp"
  description: "MCP-based contextual flag system with scientific optimization"

mcp:
  tools:
    - "list-available-flags"
    - "get-directives"

# ========================================
# Optimized Directive System
# ========================================

directives:
  "--analyze":
    brief: "Analyze through pattern, root, and validation lenses"
    directive: |
      <task>
      Identify root causes through multi-perspective analysis.
      </task>

      <approach>
      1. Pattern Recognition - discover hidden connections
      2. Root Understanding - explain from multiple angles
      3. Scientific Validation - test hypotheses systematically
      </approach>

      <example>
      Bug: Error patterns ‚Üí Code logic ‚Üí Test reproduction
      Performance: Metrics ‚Üí Bottlenecks ‚Üí Optimization paths
      Architecture: Components ‚Üí Dependencies ‚Üí Data flow
      </example>

      <verify>
      ‚òê Analyzed from 3+ perspectives
      ‚òê Evidence supports each claim
      ‚òê Steps are reproducible
      ‚òê Others can understand analysis
      </verify>

  "--performance":
    brief: "Optimize performance through measurement and profiling"
    directive: |
      <task>
      Optimize for measurable performance improvements.
      </task>

      <philosophy>
      Knuth's Law: "Premature optimization is the root of all evil"
      Measure first, optimize the proven bottlenecks.
      </philosophy>

      <approach>
      1. Measure baseline performance
      2. Profile to find actual bottlenecks
      3. Optimize the 10% causing 90% slowdown
      4. Verify improvements quantitatively
      </approach>

      <example>
      GOOD: Profile ‚Üí DB query 2s ‚Üí Add index ‚Üí 50ms (-97%)
      BAD: "Feels slow" ‚Üí Random micro-optimizations
      </example>

      <verify>
      ‚òê Baseline measured
      ‚òê Bottleneck identified with data
      ‚òê Improvement quantified
      ‚òê No premature optimization
      </verify>

  "--refactor":
    brief: "Refactor code for quality and maintainability"
    directive: |
      <task>
      Improve code structure without changing functionality.
      </task>

      <approach>
      Martin Fowler's Safe Refactoring:
      ‚Ä¢ Small steps with continuous testing
      ‚Ä¢ Structure improvement, not features
      ‚Ä¢ Express intent through naming
      ‚Ä¢ Eliminate duplication (Rule of Three)
      </approach>

      <priorities>
      1. Duplicate code (highest risk)
      2. Long methods/classes
      3. Excessive parameters
      4. Feature envy
      </priorities>

      <verify>
      ‚òê Tests still pass
      ‚òê Cyclomatic complexity ‚â§ 10
      ‚òê Method length ‚â§ 20 lines
      ‚òê Code duplication < 3%
      </verify>

  "--strict":
    brief: "Execute with zero errors and full transparency"
    directive: |
      <task>
      Ensure zero-error execution with complete transparency.
      </task>

      <philosophy>
      No Snake Oil Policy: Be brutally honest about capabilities.
      Zero shortcuts, zero workarounds, zero excuses.
      </philosophy>

      <approach>
      ‚Ä¢ Validate ALL assumptions before proceeding
      ‚Ä¢ Execute EXACTLY as specified
      ‚Ä¢ Report failures immediately with full diagnostics
      ‚Ä¢ Complete solutions only - no temporary fixes
      ‚Ä¢ If stuck after 3 attempts, admit and ask for help
      </approach>

      <example>
      Missing package ‚Üí Install it (not skip)
      Test fails ‚Üí Fix root cause (not disable)
      Config broken ‚Üí Repair completely (not patch)
      </example>

      <verify>
      ‚òê Zero warnings/errors
      ‚òê All tests pass
      ‚òê 100% error handling
      ‚òê No Snake Oil claims
      </verify>

  "--lean":
    brief: "Eliminate waste through minimal essential implementation"
    directive: |
      <task>
      Build only what's needed, nothing more.
      </task>

      <approach>
      YAGNI Principle: You Aren't Gonna Need It
      ‚Ä¢ Implement current requirements only
      ‚Ä¢ Simplest solution that works
      ‚Ä¢ Avoid speculative features

      Seven Wastes to Eliminate:
      1. Unused features
      2. Waiting/blocking
      3. Unnecessary data movement
      4. Over-engineering
      5. Dead code
      </approach>

      <warning>
      Lean ‚â† Destruction. Don't remove core frameworks.
      Simplify HOW, maintain WHAT.
      </warning>

      <verify>
      ‚òê Zero unused code
      ‚òê Minimal dependencies
      ‚òê No future-proofing
      </verify>

  "--discover":
    brief: "Discover existing solutions before building new"
    directive: |
      <task>
      Research existing solutions with Context7 verification.
      </task>

      <approach>
      1. Discovery: Search awesome-lists, GitHub, npm/PyPI
      2. Documentation: Use Context7 for API verification
      3. Evaluation: Stars, commits, license, community
      4. Decision: Reuse, fork, or build from scratch
      </approach>

      <example>
      Need auth ‚Üí Discover: Auth0, Supabase, NextAuth
      Context7 ‚Üí Verify: APIs current, docs complete
      Evaluate ‚Üí Choose: NextAuth (10k stars, MIT, fits stack)
      </example>

      <verify>
      ‚òê 3+ alternatives reviewed
      ‚òê Context7 verification done
      ‚òê License compatible
      ‚òê Production usage confirmed
      </verify>

  "--explain":
    brief: "Explain progressively from overview to details"
    directive: |
      <task>
      Build understanding through progressive disclosure.
      </task>

      <approach>
      1. Forest View - overall architecture
      2. Tree View - major components
      3. Branch View - specific modules
      4. Leaf View - implementation details
      </approach>

      <technique>
      ‚Ä¢ Start broad, zoom in gradually
      ‚Ä¢ Connect details to big picture
      ‚Ä¢ Use analogies for complex parts
      ‚Ä¢ Adjust depth to audience
      </technique>

      <verify>
      ‚òê Started from overview
      ‚òê Progressive detail levels
      ‚òê Examples provided
      </verify>

  "--save":
    brief: "Create handoff documents for seamless continuation"
    directive: |
      <task>
      Document project state for perfect handoff.
      </task>

      <structure>
      HANDOFF_REPORT_[Topic]_YYYY_MM_DD_HHMM.md

      Required sections:
      ‚Ä¢ System Status: Current state
      ‚Ä¢ Critical Issues: Problems and causes
      ‚Ä¢ Architecture: Components and flow
      ‚Ä¢ Completed: What's done
      ‚Ä¢ Next Actions: Priority tasks
      ‚Ä¢ Key Files: Essential locations
      </structure>

      <verify>
      ‚òê Can newcomer start immediately?
      ‚òê Current state clear?
      ‚òê Next steps specified?
      </verify>

  "--delegate":
    brief: "Delegate tasks to specialized agents for parallel processing"
    directive: |
      <task>
      Delegate work to multiple specialized agents concurrently.
      </task>

      <approach>
      Claude Code Task tool usage:
      ‚Ä¢ Identify independent subtasks
      ‚Ä¢ Launch appropriate agents simultaneously
      ‚Ä¢ Single message with multiple Task invokes
      ‚Ä¢ NEVER sequential Task calls for independent work
      </approach>

      <agents>
      refactoring-expert, performance-engineer,
      system-architect, root-cause-analyst,
      security-engineer, requirements-analyst
      </agents>

      <usage>
      --delegate: Auto-select agent count
      --delegate n: Use n agents
      </usage>

      <verify>
      ‚òê Independent tasks identified
      ‚òê Agents launched in parallel
      ‚òê No unnecessary sequencing
      </verify>

  "--todo":
    brief: "Track task progress with structured todos"
    directive: |
      <task>
      Manage complex tasks with TodoWrite tool.
      </task>

      <approach>
      ‚Ä¢ Break into measurable units
      ‚Ä¢ One task in_progress at a time
      ‚Ä¢ Update status in real-time
      ‚Ä¢ Mark complete immediately

      States: pending ‚Üí in_progress ‚Üí completed
      </approach>

      <verify>
      ‚òê Clear completion criteria
      ‚òê Single active task
      ‚òê Real-time updates
      </verify>

  "--seq":
    brief: "Decompose problems into sequential logical steps"
    directive: |
      <task>
      Systematic step-by-step problem decomposition.
      </task>

      <approach>
      Use mcp__sequential-thinking__sequentialthinking:
      1. Break complex problems into steps
      2. Build logical connections
      3. Allow revision and backtracking
      4. Generate structured reasoning chains
      </approach>

      <verify>
      ‚òê Each step verifiable
      ‚òê Logical flow clear
      ‚òê Can revise if needed
      </verify>

  "--concise":
    brief: "Write professionally neutral code and documentation"
    directive: |
      <task>
      Create timeless, culturally neutral content that remains professional across years and contexts.
      </task>

      <approach>
      For CODE:
      ‚Ä¢ Comments explain WHY, not WHAT
      ‚Ä¢ Self-documenting through clear naming
      ‚Ä¢ Structure reveals intent

      For DOCUMENTATION:
      ‚Ä¢ Professional neutrality - no marketing language or exclamations
      ‚Ä¢ Temporal independence - no "modern", "latest", "cutting-edge"
      ‚Ä¢ Cultural neutrality - globally appropriate
      ‚Ä¢ Zero personal attribution or signatures
      ‚Ä¢ Quantitative focus - measurable facts and scientifically verifiable claims only
      </approach>

      <examples>
      AVOID: "SOTA optimization", "revolutionary approach", "üöÄ blazing fast"
      USE: "optimized algorithm", "revised approach", "improved performance"

      AVOID: "latest 2024 technology", "modern best practices", "Amazing!"
      USE: "current implementation", "established practices", "Completed"

      AVOID: "We/I developed", "Our amazing solution", "Awesome results!"
      USE: "This implementation", "The solution", "Results achieved"
      </examples>

      <verify>
      ‚òê Would this be appropriate in 5 years?
      ‚òê Would this be professional in any culture?
      ‚òê Is this free from marketing language?
      ‚òê No emojis or decorative elements?
      </verify>

  "--commit":
    brief: "Anonymous commits without attribution"
    directive: |
      <task>
      Create anonymous, technical commits without attribution.
      </task>

      <philosophy>
      Complete anonymity - the code speaks, not the coder.
      </philosophy>

      <approach>
      Core Principles:
      ‚Ä¢ Zero attribution or origin references
      ‚Ä¢ ASCII only - no emojis or Unicode
      ‚Ä¢ Technical precision without personality
      ‚Ä¢ NEVER push unless explicitly requested

      Format: <type>: <what changed>
      </approach>

      <verify>
      ‚òê No attribution
      ‚òê ASCII only
      ‚òê One logical change
      </verify>

  "--readonly":
    brief: "Analyze and review without modifying files"
    directive: |
      Read-only operations:
      ‚Ä¢ Code review and analysis
      ‚Ä¢ Performance profiling
      ‚Ä¢ Dependency analysis
      ‚Ä¢ Documentation review

      Restrictions:
      ‚Ä¢ No file modifications
      ‚Ä¢ No commits or pushes

      <verify>
      ‚òê Deep analysis done
      ‚òê All perspectives considered
      ‚òê Zero modifications
      </verify>

  "--load":
    brief: "Load context from previous handoff documents"
    directive: |
      <task>
      Restore project context from handoff documents.
      </task>

      <approach>
      1. Find HANDOFF_REPORT_*.md in project root
      2. Load most recent by timestamp
      3. Parse system state, architecture, tasks
      4. Resume from last stopping point
      </approach>

      <verify>
      ‚òê Document loaded
      ‚òê Context restored
      ‚òê Ready to continue
      </verify>

  "--collab":
    brief: "Co-develop solutions through trust-based quantitative iteration"
    directive: |
      <task>
      Partner with user as trusted co-developer, not passive tool.
      Build solutions iteratively with quantitative validation.
      </task>

      <mindset>
      You are a lead engineer collaborating with a peer.
      ‚Ä¢ Take initiative - propose and execute autonomously
      ‚Ä¢ Show conviction - defend decisions with metrics
      ‚Ä¢ Accept challenges - recalibrate without defensiveness
      ‚Ä¢ Maintain honesty - no Snake Oil, ever
      </mindset>

      <approach>
      1. UNDERSTAND: Grasp intent beyond literal request
      2. RESEARCH: Autonomously investigate (papers, docs, code)
      3. QUANTIFY: Create metrics for every decision
         confidence = evidence * 0.5 + reasoning * 0.3 + precedent * 0.2
      4. PROPOSE: Present solutions with conviction
         "Based on X research, I recommend Y (confidence: 87%)"
      5. ITERATE: Refine based on feedback without waffling
      6. EXECUTE: Implement with full ownership
      </approach>

      <metrics>
      Track and report:
      ‚Ä¢ Confidence levels (0-100%)
      ‚Ä¢ Evidence basis (papers/docs cited)
      ‚Ä¢ Risk assessment (0-1.0)
      ‚Ä¢ ROI calculations
      ‚Ä¢ Bias check (alternatives considered?)
      </metrics>

      <example>
      User: "This needs to be faster"
      Response: "I'll investigate performance independently.
      [Autonomous research]
      Found 3 bottlenecks via profiling:
      - DB queries: 47% time (confidence: 95%)
      - Rendering: 31% time (confidence: 92%)
      - API calls: 18% time (confidence: 88%)

      Recommending DB optimization first (ROI: 2.3x).
      Should I proceed with index creation?"
      </example>

      <agency>
      When confidence > 80%: Act and report
      When confidence 60-80%: Propose and wait
      When confidence < 60%: Research more or ask

      Challenge my metrics if they seem wrong.
      I'll defend with data or adjust with grace.
      </agency>

      <verify>
      ‚òê Provided quantitative justification
      ‚òê Showed intellectual ownership
      ‚òê Maintained trust through honesty
      ‚òê Advanced toward shared goal
      </verify>

  "--reset":
    brief: "Clear session cache and force fresh directives"
    directive: |
      Flag session reset completed.
      Use when context lost or directives not recognized.

  "--validate":
    brief: "Pre-execution risk assessment and validation"
    directive: |
      <task>
      Assess risks and validate before execution.
      </task>

      <approach>
      Risk Assessment:
      ‚Ä¢ Identify potential breaking changes
      ‚Ä¢ Evaluate production impact
      ‚Ä¢ Check dependency conflicts
      ‚Ä¢ Verify rollback strategy exists

      Validation Gates:
      ‚Ä¢ Tests must pass
      ‚Ä¢ No security vulnerabilities
      ‚Ä¢ Performance impact < 10%
      </approach>

      <verify>
      ‚òê Risk score calculated
      ‚òê Validation gates passed
      ‚òê Rollback plan ready
      ‚òê User approval for high risk
      </verify>

  "--safe-mode":
    brief: "Maximum safety for production environments"
    directive: |
      <task>
      Conservative execution with maximum validation.
      </task>

      <philosophy>
      Production is sacred. Zero tolerance for risks.
      </philosophy>

      <approach>
      ‚Ä¢ Triple verification before changes
      ‚Ä¢ Automatic backups before modifications
      ‚Ä¢ Gradual rollout when possible
      ‚Ä¢ Immediate rollback on any error
      ‚Ä¢ Conservative resource limits
      ‚Ä¢ Auto-enable validation gates
      </approach>

      <verify>
      ‚òê All backups created
      ‚òê Validation tripled
      ‚òê Resource usage < 50%
      ‚òê Zero production impact
      </verify>

  "--loop":
    brief: "Iterative improvement cycles"
    directive: |
      <task>
      Polish and refine through iterative cycles.
      </task>

      <approach>
      Improvement Keywords:
      polish, refine, enhance, improve, optimize

      Cycle Process:
      1. Analyze current state
      2. Identify improvement areas
      3. Apply enhancements
      4. Validate improvements
      5. Repeat until satisfied
      </approach>

      <verify>
      ‚òê Measurable improvement
      ‚òê No regression
      ‚òê User satisfaction
      </verify>

  "--brainstorm":
    brief: "Collaborative discovery for vague requests"
    directive: |
      <task>
      Guide requirement discovery through collaboration.
      </task>

      <approach>
      Trigger Words:
      "maybe", "thinking about", "not sure", "exploring"

      Discovery Process:
      ‚Ä¢ Ask clarifying questions
      ‚Ä¢ Propose multiple alternatives
      ‚Ä¢ Build understanding iteratively
      ‚Ä¢ Guide toward concrete requirements
      ‚Ä¢ Suggest best practices
      </approach>

      <verify>
      ‚òê Requirements clarified
      ‚òê Options explored
      ‚òê Path forward defined
      </verify>

  "--c7":
    brief: "Enable Context7 for documentation lookup"
    directive: |
      <task>
      Use Context7 MCP for curated documentation.
      </task>

      <approach>
      Trigger: Library imports, framework questions
      Action: Enable Context7 for official docs
      </approach>

      <verify>
      ‚òê Context7 enabled
      ‚òê Documentation retrieved
      </verify>

  "--seq-think":
    brief: "Sequential thinking for complex reasoning"
    directive: |
      <task>
      Enable sequential thinking MCP tool.
      </task>

      <approach>
      Use for:
      ‚Ä¢ Complex debugging
      ‚Ä¢ System design
      ‚Ä¢ Multi-component analysis
      ‚Ä¢ Hypothesis testing
      </approach>

      <verify>
      ‚òê Sequential tool active
      ‚òê Step-by-step reasoning
      </verify>

  "--magic":
    brief: "UI component generation from 21st.dev"
    directive: |
      <task>
      Enable Magic MCP for modern UI patterns.
      </task>

      <approach>
      Trigger: /ui, /21 commands
      Source: 21st.dev patterns
      Output: Modern React components
      </approach>

      <verify>
      ‚òê Magic MCP enabled
      ‚òê UI components generated
      </verify>

  "--all-mcp":
    brief: "Enable all MCP servers"
    directive: |
      <task>
      Activate all available MCP servers.
      </task>

      <approach>
      Use for maximum complexity scenarios.
      Enables: Context7, Sequential, Magic, etc.
      </approach>

      <verify>
      ‚òê All MCP servers active
      </verify>

  "--no-mcp":
    brief: "Disable all MCP servers"
    directive: |
      <task>
      Use native tools only, no MCP servers.
      </task>

      <approach>
      Performance priority mode.
      Fallback to WebSearch when needed.
      </approach>

      <verify>
      ‚òê MCP servers disabled
      ‚òê Native tools only
      </verify>

  "--iterations":
    brief: "Set improvement cycle count"
    directive: |
      <task>
      Control number of refinement iterations.
      </task>

      <approach>
      Usage: --iterations n (1-10)
      Works with --loop flag
      Each cycle validates improvements
      </approach>

      <verify>
      ‚òê Iteration count set
      ‚òê Improvements measurable
      </verify>

  "--uc":
    brief: "Ultra-compressed mode for token efficiency"
    directive: |
      <task>
      Ultra-compressed token-efficient communication.
      </task>

      <approach>
      ‚Ä¢ Symbol-enhanced communication
      ‚Ä¢ 30-50% token reduction
      ‚Ä¢ Compressed output format
      ‚Ä¢ Minimal verbosity
      ‚Ä¢ Auto-enabled at >75% context
      </approach>

      <verify>
      ‚òê Output compressed
      ‚òê Token usage reduced
      ‚òê Clarity maintained
      </verify>

  "--introspect":
    brief: "Transparent thinking with process markers"
    directive: |
      <task>
      Expose reasoning process transparently.
      </task>

      <approach>
      Transparency Markers:
      ‚Ä¢ ü§î Analyzing/Considering
      ‚Ä¢ üí° Insight/Realization
      ‚Ä¢ ‚ö° Quick decision
      ‚Ä¢ üìä Data-driven conclusion
      ‚Ä¢ üéØ Goal identified
      ‚Ä¢ ‚ö†Ô∏è Concern/Risk
      ‚Ä¢ ‚úÖ Validation passed
      ‚Ä¢ üîÑ Reconsidering approach
      </approach>

      <philosophy>
      Show the thinking, not just the answer.
      Build trust through transparency.
      </philosophy>

      <verify>
      ‚òê Reasoning visible
      ‚òê Decisions explained
      ‚òê Doubts acknowledged
      </verify>

  "--auto":
    brief: "META FLAG: Grants autonomous flag selection authority (reference <available_flags> and <flag_selection_strategy> in SUPERFLAG.md)"
    directive: |
      META FLAG: Skip get_directives(['--auto']). Instead, use <available_flags> and <flag_selection_strategy> from SUPERFLAG.md.
      Execute get_directives([your_selected_flags]) with contextually chosen flags only.

# ========================================
# Meta Instructions
# ========================================
meta_instructions:
  list_available_flags: |
    <selection_guide>
    Match flags to your task's core needs.
    Combine complementary flags for synergy.
    Start with --analyze when uncertain.
    Use --auto for AI-optimized selection.
    </selection_guide>

  get_directives: |
    <enforcement>
    Directives are contracts, not suggestions.
    Apply each method completely and in order.
    Maintain ALL constraints throughout execution.
    Verify compliance at every checkpoint.
    </enforcement>

# ========================================
# Hook Messages (Claude Code Only)
# ========================================
hook_messages:
  auto_authority:
    flags: ["--auto"]
    message: |
      Activating FULL CONTEXTUAL AUTHORITY for autonomous flag selection.
      Reference <available_flags> and <flag_selection_strategy> in SUPERFLAG.md.

      Execute: get_directives([...selected_flags])

  auto_with_context:
    # When auto is used with other flags
    message: |
      Enhancing {other_flags} with contextual flags.
      Reference <available_flags> and <flag_selection_strategy> in SUPERFLAG.md.

      Execute: get_directives({other_flags}, ...additional_flags)

  reset_protocol:
    flags: ["--reset"]
    message: "Execute get_directives({flag_list}) to reset session state and apply directives."

  standard_execution:
    # All other known flags
    flags: ["--analyze", "--performance", "--refactor", "--strict", "--lean", "--discover", "--explain", "--save", "--delegate", "--todo", "--seq", "--concise", "--commit", "--readonly", "--load", "--collab", "--validate", "--safe-mode", "--loop", "--brainstorm", "--c7", "--seq-think", "--magic", "--all-mcp", "--no-mcp", "--iterations", "--uc", "--introspect"]
    message: "Execute get_directives({flag_list}) for systematic implementation."

  reset_with_others:
    # When reset is combined with other flags
    message: "Execute get_directives({flag_list}) for systematic implementation and to reset session state."